# 🌐 Multimodal-WebUI: Integración de la Multimodalidad de OpenAI con Python

### 📝 Descripción
Multimodal-WebUI es un proyecto educativo que demuestra de forma sencilla a los alumnos cómo integrar y explotar las capacidades multimodales de los modelos de inteligencia artificial más avanzados, como ChatGPT, ChatGPT-V, y Whisper, mediante la API de OpenAI. A través de una interfaz web intuitiva creada con Gradio, este proyecto permite a los usuarios interactuar con ChatGPT mediante texto, voz e imágenes, ofreciendo una experiencia de usuario rica y versátil que abre nuevas posibilidades en el campo de la IA.

Este proyecto tiene como objetivo mostrar la facilidad de creación y uso de interfaces web multimodales y su potencial para aplicaciones educativas, de investigación y comerciales.

### 🌟 Características
- **Interfaz Multimodal**: Permite la interacción con ChatGPT o LMStudio a través de texto, voz e imágenes.
- **Creacion de datasets**: Transoforma de forma sencilla tus documentos al formato y contenido de archivo que espera OpenAI para rentrenar sus modelos de CHAT
- **Facil Accesibilidad**: Accede de forma sencilla la interfaz estes donde estes haciendo uso de la URL generada por Gradio al ejecutarla.
- **Facilidad de Uso**: Demuestra cómo crear y utilizar interfaces web con Gradio.
- **Aplicación Versátil**: Apto para una amplia gama de aplicaciones, tanto educativas, personales como profesionales.

### 🌟 Actualizaciones
- **Ultima version**: Creacion automatizada de tus documentos al dataset esperado por OpenAI para el rentreno de sus modelos de texto. https://platform.openai.com/docs/guides/fine-tuning
- **Proximas actualizaciones**: Fine-Tunning automatico desde la interfaz de modelos tipo CHAT de OpenAI / Transcripciones y traducciones de audio automaticas en local con Python-Whisper

### 🛠 Requisitos
- Python 3.x
- Biblioteca Gradio
- Acceso a la API de OpenAI

### 🚀 Instalación
1. Clona este repositorio en tu máquina local.
2. Instala las dependencias necesarias:
pip install -r requirements.txt

### 📖 Uso
1. Obtén las claves de API necesarias para los modelos de OpenAI. https://platform.openai.com/api-keys
2. Añade tu clave API en la linea 288, substituye "your_open_api_key_here" por tu api-key.
3. Ejecuta el script principal para lanzar la interfaz web: python assistant.py
4. Interactúa con la interfaz web utilizando texto, voz o imágenes según tus necesidades.

### 🎥 Demostración
![Demostración del proyecto Multimodal-WebUI](https://github.com/404-OS/multimodal-webui/blob/main/imgs/caso-uso-personal%20.png)

### 🤝 Contribuciones
Las contribuciones son bienvenidas y muy apreciadas. Si tienes sugerencias, correcciones o mejoras, no dudes en hacer un pull request o abrir un issue.

### 📜 Licencia
Este proyecto está bajo la licencia Apache2. Consulta el archivo LICENSE para más detalles.
